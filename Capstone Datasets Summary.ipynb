{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3239fb9c",
   "metadata": {},
   "source": [
    "# Project Summary\n",
    "\n",
    "Tentatively, my project aims to build a web/mobile app which allows visual detection classification of dog breeds using deep neural networks. To this end, the datasets must consist of images of various dog breeds and corresponding breed labels. As per the requirements of this mini-project, three datasets are described below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8654d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for downloading large files\n",
    "\n",
    "import requests\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "def download_file(url, filename=None, dirname=None):\n",
    "    \"\"\"Downloads a file at `url`\n",
    "    url - URl of file to download\n",
    "    filename[optional]- filename to save as\n",
    "    dirname[optional] - directory in which to save filename\n",
    "    \"\"\"\n",
    "    if filename is None:\n",
    "        filename = url.split(os.sep)[-1]\n",
    "    if dirname is not None:\n",
    "        Path(dirname).mkdir(parents=True, exist_ok=True)\n",
    "        filename = dirname + os.sep + filename\n",
    "    \n",
    "    if Path(filename).exists():\n",
    "        print(f\"{filename} already exists. Skipping\")\n",
    "        return\n",
    "    # Get size of the file\n",
    "    CHUNK_SIZE = 16384\n",
    "    headers = requests.head(url).headers\n",
    "    size = None\n",
    "    if headers:\n",
    "        size = headers.get('content-length', None)\n",
    "        if size is not None:\n",
    "            size = float(size)/CHUNK_SIZE\n",
    "            size = math.ceil(size)\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(filename, 'wb') as f:\n",
    "            for chunk in tqdm(r.iter_content(chunk_size=16384), total=size):\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba7ece",
   "metadata": {},
   "source": [
    "# Stanford Dogs Dataset\n",
    "The [stanford dogs dataset consists](http://vision.stanford.edu/aditya86/ImageNetDogs/) of **20,580 images of 120 different dog breeds**. The dataset consists of both bounding boxes (for object detection) as well as dog breed labels. Based on discussions and leaderboards at paperswithcode, this dataset has become an important benchmark for dog breed classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a4ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell below to download Stanford Dogs data\n",
    "STANFORD_DOGS_IMAGE_URL = 'http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar'\n",
    "STANFORD_DOGS_ANNOTATIONS_URL = 'http://vision.stanford.edu/aditya86/ImageNetDogs/annotation.tar'\n",
    "STANFORD_DOGS_SPLITS_URL = 'http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ac4800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b1d4ad965d4a6ea9766cd1a7936715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download_file(STANFORD_DOGS_IMAGE_URL, dirname='stanford_dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8cdbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ca0a3b5264402793e241cf8ba25ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download_file(STANFORD_DOGS_ANNOTATIONS_URL, dirname='stanford_dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbc6633a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476854f5fabd428d824eb50ecf0f8da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download_file(STANFORD_DOGS_SPLITS_URL, dirname='stanford_dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2989417",
   "metadata": {},
   "source": [
    "# Tsinghua Dogs Dataset\n",
    "\n",
    "[Tsinghua University Dogs Dataset](https://cg.cs.tsinghua.edu.cn/ThuDogs/) is another important benchmark dataset for dogbreed classification and detection. This dataset consists of **70428 images of 130 different dog breeds**. Each dog breed has anywhere from 200 to 7449 images represented in this dataset and the sample sizes are roughly representative of frequencies of dog breeds found in China. \n",
    "\n",
    "As is the case with Stanford Dogs dataset, this dataset also consists of class labels as well as bounding boxes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db8b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell below to download Tsinghua Dogs Dataset\n",
    "TSINGHUA_DOGS_LOW_RES_IMAGES_URL = 'https://cloud.tsinghua.edu.cn/f/80013ef29c5f42728fc8/?dl=1'\n",
    "TSINGHUA_DOGS_LOW_RES_ANNOTATIONS_URL = 'https://cg.cs.tsinghua.edu.cn/ThuDogs/low-annotations.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83ed1172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low-resolution.zip already exists. Skipping\n"
     ]
    }
   ],
   "source": [
    "download_file(TSINGHUA_DOGS_LOW_RES_IMAGES_URL, filename='low-resolution.zip', dirname='tsinghua_dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf8a012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef78e8b087c844fa8c70c2e47fb75625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download_file(TSINGHUA_DOGS_LOW_RES_ANNOTATIONS_URL, dirname='tsinghua_dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edaa629",
   "metadata": {},
   "source": [
    "# Kaggle Dog Breeds Classification Dataset\n",
    "\n",
    "This is yet another dataset for **20,000 images of 120 different breeds.**. However, a drawback of this dataset is that it only consists of labels of dog breeds and not bounding boxes. However, on the plus side, the data is pre-cropped so each image represents mostly only the dog. \n",
    "\n",
    "Since this dataset is associated with a Kaggle competition, downloading it programmatically requires a Kaggle account. Please follow instructions [here](https://www.kaggle.com/docs/api) on how to use the Kaggle API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e9a8e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.12.tar.gz (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /Users/deman/anaconda3/lib/python3.7/site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil in /Users/deman/anaconda3/lib/python3.7/site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: requests in /Users/deman/anaconda3/lib/python3.7/site-packages (from kaggle) (2.25.1)\n",
      "Requirement already satisfied: tqdm in /Users/deman/anaconda3/lib/python3.7/site-packages (from kaggle) (4.64.1)\n",
      "Requirement already satisfied: urllib3 in /Users/deman/anaconda3/lib/python3.7/site-packages (from kaggle) (1.26.3)\n",
      "Requirement already satisfied: bleach in /Users/deman/anaconda3/lib/python3.7/site-packages (from kaggle) (3.3.0)\n",
      "Collecting certifi>=2023.7.22\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "\u001b[K     |████████████████████████████████| 163 kB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: webencodings in /Users/deman/anaconda3/lib/python3.7/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: packaging in /Users/deman/anaconda3/lib/python3.7/site-packages (from bleach->kaggle) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/deman/anaconda3/lib/python3.7/site-packages (from packaging->bleach->kaggle) (2.4.7)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 15.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<5,>=3.0.2 in /Users/deman/anaconda3/lib/python3.7/site-packages (from requests->kaggle) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/deman/anaconda3/lib/python3.7/site-packages (from requests->kaggle) (2.10)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.12-py3-none-any.whl size=102975 sha256=9be59da15dbe66facfa4be567468b0ed456a208fc781319554268a68f1fcd0a2\n",
      "  Stored in directory: /Users/deman/Library/Caches/pip/wheels/6d/00/bd/a7b836e7e94f733cef5a0f274b7e991c045a6ab60cfd285fdd\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, certifi, python-slugify, kaggle\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2020.12.5\n",
      "    Uninstalling certifi-2020.12.5:\n",
      "      Successfully uninstalled certifi-2020.12.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-build 3.17.8 requires lief, which is not installed.\u001b[0m\n",
      "Successfully installed certifi-2024.2.2 kaggle-1.6.12 python-slugify-8.0.4 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d52c14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you've downloaded kaggle.json based on instructions above\n",
    "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
    "# so move it there.\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "\n",
    "\n",
    "# This permissions change avoids a warning on Kaggle tool startup.\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cfa21a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dog-breed-identification.zip to /Users/deman/Dev/SpringboardCapstone/CapstoneDatasets\n",
      "100%|███████████████████████████████████████▉| 690M/691M [00:10<00:00, 75.7MB/s]\n",
      "100%|████████████████████████████████████████| 691M/691M [00:10<00:00, 66.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "#download the dataset for the dog-breed identification challenge https://www.kaggle.com/c/dog-breed-identification\n",
    "!kaggle competitions download -c dog-breed-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9b2f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
